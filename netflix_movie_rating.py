# -*- coding: utf-8 -*-
"""netflix_movie_rating.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LsyxPfIwxf2DsDRQyndLNDIaRff5Ghdt
"""

import numpy as np
import pandas as pd
import os
from PIL import Image
from sklearn.model_selection import train_test_split

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd

file_path = '/content/drive/MyDrive/a1/ratings.train'

df = pd.read_csv(
    file_path,
    sep=r'\s+',        # whitespace-separated
    engine='python',
    header=None,
    skiprows=1         # skip the first line (73562)
)

df.columns = ['user', 'movie', 'rating']


print(df.shape)
df.head()

user_ids = df['user'].unique() #number of unique user id's
movie_ids = df['movie'].unique() #number of unique movies

#form a dictonary also we can say mapping,eg=603:0,1234:1 etc

user_map = {u: i for i, u in enumerate(user_ids)}
movie_map = {m: j for j, m in enumerate(movie_ids)}

#add two more columns user_idx and movie_idx

df['user_idx'] = df['user'].map(user_map)
df['movie_idx'] = df['movie'].map(movie_map)

num_users = len(user_ids) #length of col
num_movies = len(movie_ids) #length of rows

print("Users:", num_users, "Movies:", num_movies)
df.head(5)

from sklearn.model_selection import train_test_split

train_df, temp_df = train_test_split(
    df, test_size=0.30, random_state=42
)

val_df, test_df = train_test_split(
    temp_df, test_size=0.50, random_state=42
)
print(train_df.shape)
print(val_df.shape)
print(test_df.shape)

import numpy as np

def create_matrix(data, num_users, num_movies):
    V = np.full((num_users, num_movies), np.nan)
    for _, row in data.iterrows():
        V[int(row['user_idx']), int(row['movie_idx'])] = row['rating']
    return V

V_train = create_matrix(train_df, num_users, num_movies)
V_val   = create_matrix(val_df, num_users, num_movies)
V_test  = create_matrix(test_df, num_users, num_movies)
print(V_train.shape)
print(V_val.shape)
for i in range(2):
    for j in range(2):
        print(f"V_train[{i}][{j}] = {V_train[i][j]}")
        print(f"V_val[{i}][{j}] = {V_val[i][j]}")

import numpy as np
import math

def matfact(v, k, lr, lam, iterations):
    print("learning rate:", lr,
          "& lambda:", lam,
          "& iterations:", iterations,
          "rank:", k)

    # dimensions of rating matrix
    [m, n] = v.shape

    # initialize latent matrices
    w = np.random.rand(m, k)   # user latent matrix
    h = np.random.rand(k, n)   # movie latent matrix

    # training loop
    for itr in range(iterations):
        for i in range(m):
            for j in range(n):
                # only update if rating exists
                if not math.isnan(v[i][j]):

                    # prediction error
                    pred = np.dot(w[i], h[:, j])

                    # gradient w.r.t user factors
                    difw = (pred - v[i][j]) * h[:, j]
                    difw += lam * w[i]
                    w[i] = w[i] - lr * difw

                    # gradient w.r.t movie factors
                    difh = (pred - v[i][j]) * w[i]
                    difh += lam * h[:, j]
                    h[:, j] = h[:, j] - lr * difh

    return w, h

k = 10
iterations = 15
lam = 0.2
lr = 0.05

w, h = matfact(V_train, k, lr, lam, iterations)

print("W shape:", w.shape)
print("H shape:", h.shape)

print("First user vector:\n", w[0])
print("First movie vector:\n", h[:, 0])

vnew = np.matmul(w, h)
vnew = np.clip(vnew, a_min=0.5, a_max=5)
print(np.min(vnew), np.max(vnew))

print(vnew.shape)
for i in range(4):
    for j in range(4):
        print(f"vnew[{i}][{j}] = {vnew[i][j]}")

print("original value :",V_train.shape)
print("Predicted V shape:", vnew.shape)

user = 0
movie = 0

print("Actual rating:", V_train[user][movie])
print("Predicted rating:", vnew[user][movie])

def rmse(V_true, V_pred):
    error = 0

    count = 0
    for i in range(V_true.shape[0]):
        for j in range(V_true.shape[1]):
            if not np.isnan(V_true[i][j]):
                error += (V_true[i][j] - V_pred[i][j])**2
                count += 1
    return np.sqrt(error / count)

train_rmse = rmse(V_train, vnew)
val_rmse = rmse(V_val, vnew)
test_rmse = rmse(V_test,vnew)
print("Training RMSE:", train_rmse)
print("validation RMSE:", val_rmse)
print("Testing RMSE:", test_rmse)

# Hyperparameter search space
 lambda_list = [0.1, 0.2, 0.3, 0.4, 0.5]
lr_list     = [0.01, 0.02, 0.03, 0.04, 0.05]
k_list      = [5, 10, 20, 30, 40, 50]

best_rmse = float('inf')
best_params = None

for lam in lambda_list:
    for lr in lr_list:
        for k in k_list:

            # Train model on training data
            w, h = matfact(V_train, k, lr, lam, iterations)

            # Predict full rating matrix
            vnew = np.matmul(w, h)
            vnew = np.clip(vnew, 0.5, 5)

            # Compute RMSE
            train_rmse = rmse(V_train, vnew)
            val_rmse   = rmse(V_val, vnew)

            # Track best hyperparameters
            if val_rmse < best_rmse:
                best_rmse = val_rmse
                best_params = (lam, lr, k)

            # Logging
            print(f"lambda={lam}, lr={lr}, k={k}")
            print(f"Train RMSE: {train_rmse:.4f}")
            print(f"Val RMSE  : {best_rmse:.4f}")
            print("-" * 40)

print("\nâœ… Best Hyperparameters Found")
print("lambda, lr, k =", best_params)
print("Best Validation RMSE =", best_rmse)